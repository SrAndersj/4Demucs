{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoDSau5K9ibz"
      },
      "source": [
        "#Demucs\n",
        "\n",
        "Demucs is a music source seperation model from Facebook. Provide it a song and it will seperate the track into individual files containing drums, bass, vocals, and \"other\".\n",
        "\n",
        "[Github Repo](https://github.com/facebookresearch/demucs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECoHai3f-dHz",
        "outputId": "e7269f95-876b-4e45-ca18-807aade688aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting demucs\n",
            "  Downloading demucs-4.0.1.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m77.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting dora-search\n",
            "  Downloading dora_search-0.1.12.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 KB\u001b[0m \u001b[31m33.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 KB\u001b[0m \u001b[31m50.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting julius>=0.2.3\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 KB\u001b[0m \u001b[31m41.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting lameenc>=1.2\n",
            "  Downloading lameenc-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 KB\u001b[0m \u001b[31m46.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting openunmix\n",
            "  Downloading openunmix-1.2.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 KB\u001b[0m \u001b[31m80.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 KB\u001b[0m \u001b[31m69.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting torch>=1.8.1\n",
            "  Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Collecting torchaudio>=0.8\n",
            "  Downloading torchaudio-2.1.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m108.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 KB\u001b[0m \u001b[31m135.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting filelock\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting networkx\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting triton==2.1.0\n",
            "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting jinja2\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 KB\u001b[0m \u001b[31m36.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1\n",
            "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "Collecting typing-extensions\n",
            "  Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting sympy\n",
            "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-nvjitlink-cu12\n",
            "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m37.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting submitit\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 KB\u001b[0m \u001b[31m68.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting treetable\n",
            "  Downloading treetable-0.2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting retrying\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m39.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:13\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Using cached MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m111.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: six>=1.7.0 in ./lib/python3.10/site-packages (from retrying->dora-search->demucs) (1.16.0)\n",
            "Collecting cloudpickle>=1.2.1\n",
            "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using legacy 'setup.py install' for demucs, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for julius, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for antlr4-python3-runtime, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for treetable, since package 'wheel' is not installed.\n",
            "Building wheels for collected packages: dora-search\n",
            "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75092 sha256=f308e33053f92ace451f6204cfb834be115cf014c5f3a0d1ae1a1def6b2213d4\n",
            "  Stored in directory: /home/srandersj/.cache/pip/wheels/b1/c2/c0/bea5cc405497284d584b958f293ef32c23bad42ae5e44d973c\n",
            "Successfully built dora-search\n",
            "Installing collected packages: mpmath, lameenc, antlr4-python3-runtime, typing-extensions, treetable, tqdm, sympy, retrying, pyyaml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, einops, cloudpickle, triton, submitit, omegaconf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchaudio, julius, dora-search, openunmix, demucs\n",
            "  Running setup.py install for antlr4-python3-runtime ... \u001b[?25ldone\n",
            "\u001b[?25h  Running setup.py install for treetable ... \u001b[?25ldone\n",
            "\u001b[?25h  Running setup.py install for julius ... \u001b[?25ldone\n",
            "\u001b[?25h  Running setup.py install for demucs ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed MarkupSafe-2.1.3 antlr4-python3-runtime-4.9.3 cloudpickle-3.0.0 demucs-4.0.1 dora-search-0.1.12 einops-0.7.0 filelock-3.13.1 fsspec-2023.12.2 jinja2-3.1.3 julius-0.2.7 lameenc-1.7.0 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 openunmix-1.2.1 pyyaml-6.0.1 retrying-1.3.4 submitit-1.5.1 sympy-1.12 torch-2.1.2 torchaudio-2.1.2 tqdm-4.66.1 treetable-0.2.5 triton-2.1.0 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install demucs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/srandersj/Escritorio/4Demucs/1mi_entorno_Demucs\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "GPU: NVIDIA GeForce RTX 4060 Ti\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Verifica si CUDA (el driver de la GPU de NVIDIA) está disponible\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "# Imprime si CUDA está disponible o no\n",
        "print(f\"CUDA available: {cuda_available}\")\n",
        "\n",
        "# Si CUDA está disponible, imprime el modelo de la GPU\n",
        "if cuda_available:\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QibnBixahElY"
      },
      "source": [
        "Upload your file to Colab, then copy the path below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iXfkyi0_IUU",
        "outputId": "0c7ec6a1-b4eb-403a-832b-906bad84e54f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/demucs/hybrid_transformer/955717e8-8726e21a.th\" to /home/srandersj/.cache/torch/hub/checkpoints/955717e8-8726e21a.th\n",
            "100%|██████████████████████████████████████| 80.2M/80.2M [00:49<00:00, 1.70MB/s]\n",
            "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
            "Separated tracks will be stored in /home/srandersj/Escritorio/4Demucs/1mi_entorno_Demucs/separated/htdemucs\n",
            "Separating track Calibre 50 - Si Te Pudiera Mentir (LETRA).mp3\n",
            "100%|████████████████████████████████████████████████████████████████████████| 257.4/257.4 [00:05<00:00, 42.95seconds/s]\n"
          ]
        }
      ],
      "source": [
        "!python -m demucs.separate 'Calibre 50 - Si Te Pudiera Mentir (LETRA).mp3'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
